{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit4918b2b51f7e4ba889a6a37bf4e61f47",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4760, 3)\n(3440, 3)\nRecompute the normal of the downsampled point cloud\n(33, 4760)\n0.0\n"
    }
   ],
   "source": [
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "voxel_size = 0.05\n",
    "radius_feature = voxel_size * 5\n",
    "# Downsample\n",
    "source_downsampled = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target_downsampled = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "print(np.asarray(source_downsampled.points).shape)\n",
    "print(np.asarray(target_downsampled.points).shape)\n",
    "\n",
    "# Estimating normals of the pointcloud points using\n",
    "print(\"Recompute the normal of the downsampled point cloud\")\n",
    "source_downsampled.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "target_downsampled.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "# o3d.visualization.draw_geometries([source, target])\n",
    "\n",
    "# Compute features\n",
    "source_fpfh = o3d.registration.compute_fpfh_feature(source_downsampled, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "target_fpfh = o3d.registration.compute_fpfh_feature(target_downsampled, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "\n",
    "print(source_fpfh.data.shape)\n",
    "print(source_fpfh.data[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Rotation is: [[-0.61443129 -0.76591287 -0.18934538]\n [-0.62953042  0.62059486 -0.46749702]\n [ 0.47556875 -0.16804612 -0.86347835]], \n\n---------\n\nTranslation is: [5.16161616 2.77595231 2.20057141]\n"
    }
   ],
   "source": [
    "search_kd = o3d.geometry.KDTreeFlann(target_fpfh)\n",
    "\n",
    "def random_points_kabsch(source_downsampled, target_downsampled, source_fpfh, target_fpfh, search_kd):\n",
    "\n",
    "    source_down = np.asarray(source_downsampled.points)\n",
    "    target_down = np.asarray(target_downsampled.points)\n",
    "\n",
    "    # Get 3 random points\n",
    "    number_of_nearest_neighbours = 10\n",
    "\n",
    "    source_points = []\n",
    "    target_points = []\n",
    "    for i in range(5):\n",
    "        random_point = random.randint(0, source_fpfh.data.shape[0]-1)\n",
    "        source_point_fpfh = source_fpfh.data[:, random_point]\n",
    "        source_points.append(np.asarray(source_downsampled.points)[random_point, :])\n",
    "        [_, idx, _] = search_kd.search_knn_vector_xd(source_point_fpfh, number_of_nearest_neighbours)\n",
    "        random_match = random.randint(0, number_of_nearest_neighbours-1)\n",
    "        target_points.append(np.asarray(target_downsampled.points)[idx[random_match], :])\n",
    "\n",
    "    source_points = np.array(source_points)\n",
    "    target_points = np.array(target_points)\n",
    "\n",
    "    # Calculate centroids\n",
    "    centroid_source = np.sum(source_down, axis=0)/source_down.shape[0]\n",
    "    centroid_target = np.sum(target_down, axis=0)/target_down.shape[0]\n",
    "\n",
    "    # Subtract centroids from random chosen points\n",
    "    source_points_cen = source_points - centroid_source\n",
    "    target_points_cen = target_points - centroid_source\n",
    "\n",
    "    # Cross variance\n",
    "    C = np.transpose(source_points_cen) @ target_points_cen\n",
    "\n",
    "    # SVD on covariance\n",
    "    U, S, V = np.linalg.svd(C)\n",
    "\n",
    "    R = U @ np.transpose(V)\n",
    "    T = centroid_target - R @ centroid_source\n",
    "\n",
    "    return R, T, source_points, target_points\n",
    "\n",
    "R, T, source_points_cen, target_points_cen = random_points_kabsch(source_downsampled, target_downsampled, source_fpfh, target_fpfh, search_kd)\n",
    "print(f'Rotation is: {R}, \\n\\n---------\\n\\nTranslation is: {T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "11.898521645400946\n9.50421409551969\n7.038849798616178\n5.024971065255992\n"
    }
   ],
   "source": [
    "run_ransac = 10\n",
    "\n",
    "distance_ = np.inf\n",
    "for i in range(run_ransac):\n",
    "    R, T, source_points, target_points = random_points_kabsch(source_downsampled, target_downsampled, source_fpfh, target_fpfh, search_kd)\n",
    "\n",
    "    source_points = np.transpose(R @ np.transpose(source_points)) + T\n",
    "    sum_square_diff = np.sum((target_points - source_points)**2)\n",
    "    \n",
    "\n",
    "    if distance_ > sum_square_diff:\n",
    "        print(sum_square_diff)\n",
    "        distance_ = sum_square_diff\n",
    "        transform_matrix = np.zeros([4, 4])\n",
    "        transform_matrix[:3, :3] = R\n",
    "        transform_matrix[:3, 3] = T\n",
    "        transform_matrix[3, 3] = 1\n",
    "        \n",
    "        #source_downsampled = source_downsampled.transform(transform_matrix)\n",
    "\n",
    "\n",
    "draw_registrations(source, target, transform_matrix, True)\n",
    "\n"
   ]
  }
 ]
}